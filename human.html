<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Human oversight &#8212; Trustworthy AI  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Privacy and data governance" href="privacydatagov.html" />
    <link rel="prev" title="Trustworthy AI" href="index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.12.4.min.js "></script>
<script type="text/javascript" src="_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="_static/bootstrap-3.4.1/js/bootstrap.min.js "></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          Trustworthy AI</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Documentation <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Human oversight</a></li>
<li class="toctree-l1"><a class="reference internal" href="privacydatagov.html">Privacy and data governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="robustnesssafety.html">Technical robustness and security</a></li>
<li class="toctree-l1"><a class="reference internal" href="transparencyexplicability.html">Transparency and explicability</a></li>
<li class="toctree-l1"><a class="reference internal" href="diversitynondiscrimination.html">Diversity, non discrimination and fairness</a></li>
<li class="toctree-l1"><a class="reference internal" href="environmentalsocietal.html">Environmental and societal well-being</a></li>
<li class="toctree-l1"><a class="reference internal" href="accountability.html">Accountability</a></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">Bibliography</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Human oversight</a><ul>
<li><a class="reference internal" href="#guidelines-depending-on-the-ai-system-lifecyle">Guidelines depending on the AI system lifecyle</a></li>
<li><a class="reference internal" href="#risk-criticality">Risk &amp; criticality</a></li>
<li><a class="reference internal" href="#appendix-recommendations-from-the-eu">Appendix - Recommendations from the EU</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="index.html" title="Previous Chapter: Trustworthy AI"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Trustworthy AI</span>
    </a>
  </li>
  <li>
    <a href="privacydatagov.html" title="Next Chapter: Privacy and data governance"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Privacy and d... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <section id="human-oversight">
<h1>Human oversight<a class="headerlink" href="#human-oversight" title="Permalink to this headline">¶</a></h1>
<p>As stated by the EU, “human oversight ensures that an AI system does not undermine human autonomy or cause other adverse effects”.</p>
<section id="guidelines-depending-on-the-ai-system-lifecyle">
<h2>Guidelines depending on the AI system lifecyle<a class="headerlink" href="#guidelines-depending-on-the-ai-system-lifecyle" title="Permalink to this headline">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Phase</p></th>
<th class="head"><p>Guideline</p></th>
<th class="head"><p>Practical consequences</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Conception (prior to AI system development)</p></td>
<td><p>AI contributors should always assess “why” they set up an AI system prior to actually doing it</p></td>
<td><p><span class="raw-html-m2r"><ul><li>What is the end goal?</li><li>How much does it benefit to people? Is there a risk of attempting to fundamental rights? If so, have the said risk(s) been assessed (see section below)?</li><li>What are the potential social and environmental consequences?</li><li>Overall, did the AI system receive external clearance (external to AI practitioners about to implement it)?</li></ul></span></p></td>
</tr>
<tr class="row-odd"><td><p>Use (after AI system development)</p></td>
<td><p>Users of an AI system must be able to control it</p></td>
<td><p><span class="raw-html-m2r"><ul><li>AI contributors must make it clear for users that they interact with an AI system (in the sense that it must not be hidden) to avoid "unfair manipulation, herding[,] conditioning, [...]"</li></li><li>AI contributors must make it easy for users to:<ul><li>Interact with the AI system through clear documentation</li><li>Regularly challenge and audit the AI system (through a clear and shared operating model detailed early in the AI system lifecyle e.g.)</li><li>Stop the AI system in case of potential harm</li></ul></span><span class="raw-html-m2r"><li>AI contributors should ease human intervention, according to one or more of the following approaches:<ul><li>Human-in-command (HIC)</li></span><span class="raw-html-m2r"><li>Human-in-the-loop (HITL)</li></span><span class="raw-html-m2r"><li>Human-on-the-loop (HOTL)*</li></span>&lt;/ul&gt;&lt;/ul&gt;</p></td>
</tr>
</tbody>
</table>
<p><span class="raw-html-m2r"><b>* Definitions</b></span> (inspired by EU):</p>
<ul class="simple">
<li><p>Human-in-the-loop (HITL): human intervention in every decision of the AI system</p></li>
<li><p>Human-on-the-loop (HOTL): human intervention during the design of the AI system, and while the AI system operates, through monitoring e.g.</p></li>
<li><p>Human-in-command (HIC): humans oversee the AI system and its implications, with the possibility to decide when and how to use it</p></li>
</ul>
</section>
<section id="risk-criticality">
<h2>Risk &amp; criticality<a class="headerlink" href="#risk-criticality" title="Permalink to this headline">¶</a></h2>
<p>AI contributors must evaluate the risk and criticality of an AI system before starting to implement it, namely during ideation phases, among following risks:</p>
<ul class="simple">
<li><p><strong>Unacceptable Risk</strong>: the AI system must be banned</p></li>
<li><p><strong>High Risk</strong>: the AI system must comply with regulation enforcements (see recommendations below)</p></li>
<li><p><strong>Limited Risk</strong>: the AI system must be transparent for the user</p></li>
<li><p><strong>Minimal Risk</strong>: the AI system is not subject to regulation</p></li>
</ul>
<details>
    <summary>Definitions (<b>click to unfold</b>)</summary>

Directly quoted from <a href="https://ec.europa.eu/commission/presscorner/detail/en/IP_21_1682">ec.europa.eu</a>

<ul>
  <li><b>Unacceptable risk</b>: <i>AI systems considered a clear threat to the safety, livelihoods and rights of people [...]. This includes AI systems or applications that manipulate human behaviour to circumvent users' free will (e.g. toys using voice assistance encouraging dangerous behaviour of minors) and systems that allow ‘social scoring' by governments.</i></li>
  <li><b>High-risk AI systems include</b>:
    <ul>
      <li><i>Critical infrastructures (e.g. transport), that could put the life and health of citizens at risk</i></li>
      <li><i>Educational or vocational training, that may determine the access to education and professional course of someone's life (e.g. scoring of exams); safety components of products (e.g. AI application in robot-assisted surgery)</i></li>
      <li><i>Employment, workers management and access to self-employment (e.g. CV-sorting software for recruitment procedures);</i></li>
      <li><i>Essential private and public services (e.g. credit scoring denying citizens opportunity to obtain a loan);</i></li>
      <li><i>Law enforcement that may interfere with people's fundamental rights (e.g. evaluation of the reliability of evidence)</i></li>
      <li><i>Migration, asylum and border control management (e.g. verification of authenticity of travel documents);</i></li>
      <li><i>Administration of justice and democratic processes (e.g. applying the law to a concrete set of facts)</i></li>
    </ul>
  <li><b>Limited risk</b><i> - AI system with transparency obligations: When using AI systems such as chatbots, users should be aware that they are interacting with a machine so they can take an informed decision to continue or step back.</i></li>
  <li><b>Minimal risk</b><i>: the legal proposal allows the free use of applications such as AI-enabled video games or spam filters. The vast majority of AI systems fall into this category. The draft Regulation does not intervene here, as these AI systems represent only minimal or no risk for citizens' rights or safety.</i></li>
</ul>
</details></section>
<section id="appendix-recommendations-from-the-eu">
<h2>Appendix - Recommendations from the EU<a class="headerlink" href="#appendix-recommendations-from-the-eu" title="Permalink to this headline">¶</a></h2>
<p>Below are the recommendations directly reported from <a class="reference external" href="https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai">EU</a>.</p>
<a class="reference internal image-reference" href="_images/human_1.png"><img alt="_images/human_1.png" class="align-center" src="_images/human_1.png" style="width: 60%;" /></a>
<a class="reference internal image-reference" href="_images/human_2.png"><img alt="_images/human_2.png" class="align-center" src="_images/human_2.png" style="width: 60%;" /></a>
<ul class="simple">
<li></li>
</ul>
</section>
</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright Danone, Datacraft, 2021.<br/>
    </p>
  </div>
</footer>
  </body>
</html>