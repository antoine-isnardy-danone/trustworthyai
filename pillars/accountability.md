# Accountability
Mechanisms must be put in place to ensure responsibility and accountability for AI systems and their outcomes, both before and after their deployment.

## Evaluation by internal and external auditors
Evaluation by internal and external auditors and the availability of evaluation reports can contribute to trustworthiness of AI. However, information about business models and intellectual property related to AI systems do not necessarily need to be open publicly. But in applications affecting fundamental rights, including safety critical applications, AI systems should be able to be independently audited.

As a starting point for auditing AI, one could leverage [ISACA's COBIT (2019)](https://community.mis.temple.edu/mis5203sec001sp2019/files/2019/01/COBIT-2019-Framework-Introduction-and-Methodology_res_eng_1118.pdf) framework. Explanation of how to apply this framework for AI projects (including for example metrics) can be found in this [document](https://ec.europa.eu/futurium/en/system/files/ged/auditing-artificial-intelligence.pdf).

## Identification of negative impacts
Identifying, assessing, documenting and minimising potential negative impacts of an AI system is crucial for people (in)directly affected by AI systems. Impact assessments can be helpful to minimize negative impact. Assessments must be proportionate to the risks AI systems pose.

Some examples of negative impacts of AI are the following:
- Built in biases, as it is built by humans it can have a conscious or unconscious bias.
- Some jobs might be lost because tasks are replaced by AI. 
- Change in human experience, loss of personal experience/social interaction.
- Acceleration of threats to cyber security.
- Privacy/data breach or unlawful use of data.
- Human no longer in (direct) control to overlook situations.
- Social/wealth polarization.

## Ensure redress is possible
When unjust adverse impact occurs, accessible mechanisms should be foreseen to ensure redress. National Human Rights structures (i.e. Ombudsmen and National Human Rights Institutions) can be such a source of redress, through rendering their own decisions in accordance with their respective mandates. 

Knowing that redress is possible when things go wrong is key to ensure trust.
