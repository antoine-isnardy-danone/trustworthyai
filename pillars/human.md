# Human oversight

As stated by the EU, "human oversight ensures that an AI system does not undermine human autonomy or cause other adverse effects".

## Guidelines depending on the AI system lifecyle

| Phase  | Guideline  | Practical consequences  |
|---|---|---|
| Conception (prior to AI system development)  | AI contributors should always assess “why” they set up an AI system prior to actually doing it | <ul><li>What is the end goal?</li><li>How much does it benefit to people? Is there a risk of attempting to fundamental rights? If so, have the said risk(s) been assessed?</li><li>What are the potential social and environmental consequences?</li><li>Overall, did the AI system receive external clearance (external to AI practitioners about to implement it)?</li></ul>|
| Use (after AI system development) | Users of an AI system must be able to control it | <ul><li>AI contributors must make it clear for users that they interact with an AI system (in the sense that it must not be hidden) to avoid "unfair manipulation, herding[,] conditioning, [...]"</li></li><li>AI contributors must make it easy for users to:<ul><li>Interact with the AI system through clear documentation</li><li>Regularly challenge and audit the AI system (through a clear and shared operating model detailed early in the AI system lifecyle e.g.)</li><li>Stop the AI system in case of potential harm</li></ul><li>AI contributors should ease human intervention, according to one or more of the following approaches:<ul><li>Human-in-command (HIC)</li><li>Human-in-the-loop (HITL)</li><li>Human-on-the-loop (HOTL)*</li></ul></ul>|

<b>* Definitions</b> (inspired by EU):
- Human-in-the-loop (HITL): human intervention in every decision of the AI system
- Human-on-the-loop (HOTL): human intervention during the design of the AI system, and while the AI system operates, through monitoring e.g.
- Human-in-command (HIC): humans oversee the AI system and its implications, with the possibility to decide when and how to use it

## Appendix - Recommendations from the EU
Below are the recommendations directly reported from [EU](https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai).

.. image:: ./_static/human_1.png

.. image:: ./_static/human_2.png


