.. image:: ./_static/danone.png
    :width: 70%
    :align: center

Trustworhy AI
-------------

[Read time: 45 min]

In line with the European Union (EU) recommendations, we aim to act responsibly, create and promote an AI that is lawful, ethical and robust. It is important to ensure the protection of fundamental (human) rights and user safety.

This document gathers a set of concrete guidelines, structured around 7 principles identified by the EU about AI trustworthiness. Note that it is already a bias to consider trustworthiness through that "fixed" prism (see `Going further`_). However, we believe it provides a decent coverage of all dimensions involved in AI trustworthiness.

The primary audience of this document is AI practitioners, especially because it conveys a set of technical guidelines. However, concepts are always introduced on a high level scale, before being tackled on a lower level - and technical - scale. As a result, we strongly encourage non-AI practitioners to also read it.

Content
-------

.. toctree::
   :maxdepth: 1

   human.rst
   privacydatagov.rst
   robustnesssafety.rst
   transparencyexplicability.rst
   diversitynondiscrimination.rst
   environmentalsocietal.rst
   accountability.rst

Going further
-------------

This document acts as a practical asset about AI trustworthiness, especially dedicated to AI practitioners (advice, practical methodologies, ...).

Some broader questions would still need to be answered while describing, evaluating and regulating the socio-technical world surrounding AI:

- What are our dependencies ?

- How to make sense of our activity ?

- What do we participate in ?

- What are the shifts produced by our activity ?